{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8e9b36b1-9aaa-4ee7-bb15-7a0f0091feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PREPARATION ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c79132f9-0449-466e-a2c0-48b5a4e4ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Initial Libraries\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "eb2b05ae-f383-407d-ac71-4c3a9915bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import known modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e958a7a2-374d-47d3-a404-fb036b593da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3ca31ff9-e425-47ca-93cf-bebcfb0c9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ff4afce7-0b20-4899-9e2d-4fa30910c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "08d41afb-a66b-44e0-b521-45d867d37c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read initial built CSV to notebook\n",
    "\n",
    "df = pd.read_csv('Diagnosis_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "cfb8cc67-a62d-4ff9-bcae-b1fb1ab2f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel50168</th>\n",
       "      <th>pixel50169</th>\n",
       "      <th>pixel50170</th>\n",
       "      <th>pixel50171</th>\n",
       "      <th>pixel50172</th>\n",
       "      <th>pixel50173</th>\n",
       "      <th>pixel50174</th>\n",
       "      <th>pixel50175</th>\n",
       "      <th>pixel50176</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3256 rows × 50177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.007843  0.003922  0.003922  0.003922  0.000000  0.003922  0.003922   \n",
       "2     0.450980  0.027451  0.007843  0.003922  0.015686  0.015686  0.003922   \n",
       "3     0.007843  0.011765  0.121569  0.047059  0.337255  0.435294  0.109804   \n",
       "4     0.015686  0.015686  0.007843  0.015686  0.007843  0.450980  0.380392   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3251  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3252  0.003922  0.003922  0.007843  0.003922  0.003922  0.007843  0.003922   \n",
       "3253  0.003922  0.011765  0.011765  0.007843  0.007843  0.007843  0.003922   \n",
       "3254  0.380392  0.454902  0.137255  0.007843  0.015686  0.011765  0.000000   \n",
       "3255  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        pixel8    pixel9   pixel10  ...  pixel50168  pixel50169  pixel50170  \\\n",
       "0     0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "1     0.003922  0.003922  0.003922  ...    0.011765    0.015686    0.007843   \n",
       "2     0.007843  0.007843  0.003922  ...    0.498039    0.027451    0.011765   \n",
       "3     0.450980  0.082353  0.047059  ...    0.003922    0.019608    0.007843   \n",
       "4     0.360784  0.450980  0.070588  ...    0.015686    0.007843    0.003922   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "3251  0.000000  0.000000  0.000000  ...    0.003922    0.000000    0.000000   \n",
       "3252  0.011765  0.007843  0.003922  ...    0.000000    0.000000    0.000000   \n",
       "3253  0.003922  0.003922  0.007843  ...    0.000000    0.000000    0.000000   \n",
       "3254  0.003922  0.000000  0.007843  ...    0.000000    0.000000    0.000000   \n",
       "3255  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "\n",
       "      pixel50171  pixel50172  pixel50173  pixel50174  pixel50175  pixel50176  \\\n",
       "0       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1       0.000000    0.007843    0.003922    0.003922    0.011765    0.011765   \n",
       "2       0.011765    0.011765    0.007843    0.003922    0.011765    0.011765   \n",
       "3       0.015686    0.003922    0.031373    0.027451    0.054902    0.490196   \n",
       "4       0.003922    0.007843    0.011765    0.003922    0.003922    0.011765   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3251    0.003922    0.003922    0.000000    0.000000    0.000000    0.000000   \n",
       "3252    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3253    0.023529    0.352941    0.450980    0.482353    0.035294    0.023529   \n",
       "3254    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3255    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "      diagnosis  \n",
       "0        benign  \n",
       "1        benign  \n",
       "2        benign  \n",
       "3        benign  \n",
       "4        benign  \n",
       "...         ...  \n",
       "3251        pro  \n",
       "3252        pro  \n",
       "3253        pro  \n",
       "3254        pro  \n",
       "3255        pro  \n",
       "\n",
       "[3256 rows x 50177 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking dataframe shape and content\n",
    "\n",
    "df2 = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4718c3c0-bbfb-4a0b-9490-380c30dc3fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel50168</th>\n",
       "      <th>pixel50169</th>\n",
       "      <th>pixel50170</th>\n",
       "      <th>pixel50171</th>\n",
       "      <th>pixel50172</th>\n",
       "      <th>pixel50173</th>\n",
       "      <th>pixel50174</th>\n",
       "      <th>pixel50175</th>\n",
       "      <th>pixel50176</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.101961</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3256 rows × 50177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
       "2516  0.007843  0.015686  0.015686  0.003922  0.003922  0.011765  0.015686   \n",
       "491   0.003922  0.000000  0.000000  0.000000  0.000000  0.000000  0.003922   \n",
       "3249  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3155  0.000000  0.007843  0.011765  0.003922  0.007843  0.007843  0.003922   \n",
       "2647  0.007843  0.007843  0.015686  0.007843  0.007843  0.011765  0.007843   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1319  0.423529  0.050980  0.101961  0.239216  0.043137  0.019608  0.011765   \n",
       "1890  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2551  0.184314  0.027451  0.011765  0.227451  0.074510  0.372549  0.054902   \n",
       "2059  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1848  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        pixel8    pixel9   pixel10  ...  pixel50168  pixel50169  pixel50170  \\\n",
       "2516  0.007843  0.003922  0.007843  ...    0.003922    0.007843    0.011765   \n",
       "491   0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "3249  0.000000  0.000000  0.000000  ...    0.172549    0.403922    0.082353   \n",
       "3155  0.007843  0.007843  0.007843  ...    0.003922    0.015686    0.031373   \n",
       "2647  0.003922  0.003922  0.003922  ...    0.003922    0.007843    0.003922   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "1319  0.003922  0.003922  0.003922  ...    0.000000    0.000000    0.000000   \n",
       "1890  0.000000  0.000000  0.000000  ...    0.003922    0.000000    0.000000   \n",
       "2551  0.466667  0.101961  0.478431  ...    0.000000    0.000000    0.000000   \n",
       "2059  0.000000  0.000000  0.000000  ...    0.000000    0.003922    0.003922   \n",
       "1848  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "\n",
       "      pixel50171  pixel50172  pixel50173  pixel50174  pixel50175  pixel50176  \\\n",
       "2516    0.003922    0.000000    0.007843    0.007843    0.011765    0.007843   \n",
       "491     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3249    0.364706    0.050980    0.239216    0.043137    0.011765    0.019608   \n",
       "3155    0.478431    0.054902    0.266667    0.466667    0.325490    0.031373   \n",
       "2647    0.003922    0.007843    0.000000    0.011765    0.003922    0.003922   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1319    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1890    0.003922    0.003922    0.003922    0.000000    0.000000    0.000000   \n",
       "2551    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2059    0.000000    0.000000    0.000000    0.000000    0.000000    0.003922   \n",
       "1848    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "      diagnosis  \n",
       "2516        pro  \n",
       "491      benign  \n",
       "3249        pro  \n",
       "3155        pro  \n",
       "2647        pro  \n",
       "...         ...  \n",
       "1319      early  \n",
       "1890        pre  \n",
       "2551        pro  \n",
       "2059        pre  \n",
       "1848        pre  \n",
       "\n",
       "[3256 rows x 50177 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly shuffle instances within the dataframe\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df2)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5ee980b1-5983-45a4-8384-b1e6bb61a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL GENERATION AND EVALUATION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1fb07a4c-6dd8-485b-881a-ae3a3fd73b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC MODEL METHODS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b053fd23-a9cc-45e7-8cb2-38b386240635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6334\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df.drop(\"diagnosis\", axis=1)  # Feature matrix (all pixel values)\n",
    "y = df[\"diagnosis\"]  \n",
    "\n",
    "y_array = np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = one_hot_encoder.fit_transform(y_array)\n",
    "\n",
    "tru = X\n",
    "tru['Benign'] = y_encoded[:,0]\n",
    "tru['Early'] = y_encoded[:,1]\n",
    "tru['Pre'] = y_encoded[:,2]\n",
    "tru['Pro'] = y_encoded[:,3]\n",
    "\n",
    "\n",
    "X = tru.drop(columns=['Benign', 'Early', 'Pre', 'Pro'])\n",
    "y = tru[['Benign', 'Early', 'Pre', 'Pro']]\n",
    "\n",
    "y = np.argmax(y.values, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_model = LogisticRegression(max_iter = 25000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8b6dc64d-6b24-42cc-a1d9-125fe6079b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.504601226993865\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Decision Tree\n",
    "\n",
    "from sklearn import tree\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X = df.drop(columns = \"diagnosis\")\n",
    "y_label = df[\"diagnosis\"]\n",
    "\n",
    "one_hot_y = pd.get_dummies(y_label,dtype=float)\n",
    "\n",
    "one_hot_y_array = np.array(one_hot_y)\n",
    "X_array = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, one_hot_y_array, test_size=0.2, random_state=42,)\n",
    "X_train_sparse = csr_matrix(X_train)\n",
    "\n",
    "tree_classifier = tree.DecisionTreeClassifier(random_state=42,min_samples_split=10,max_depth=25,min_samples_leaf=5, criterion=\"entropy\", )\n",
    "\n",
    "tree_model = tree_classifier.fit(X_train_sparse,y_train)\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "49e30c4f-9c93-499f-b5ed-9badea6c79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4156441717791411\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "30c8490f-bf89-45d7-a0f9-170c297eb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6104294478527608\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "y = tru[['Benign', 'Early', 'Pre', 'Pro']]\n",
    "y = np.argmax(y.values, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = SVC(kernel='linear') \n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "946ef571-8960-4376-b4c8-9dfb24739a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOOSTING MODEL METHODS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "59c09040-0b03-40f6-b371-b67e8aff2031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dimensions: 1127\n"
     ]
    }
   ],
   "source": [
    "# Reducing size to create computational feasibility\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Keep enough components to preserve 95% of variance\n",
    "pca = PCA(n_components=0.95, svd_solver='full')\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"Reduced dimensions:\", X_train_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0379a227-dd20-4f6e-a56f-8d9b22735bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2604, 1127)\n",
      "(652, 1127)\n"
     ]
    }
   ],
   "source": [
    "# Validating image array shape\n",
    "\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4fbf588a-c7c4-4b23-aaaa-1e1ff993e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy: 0.5782208588957055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.10      0.14       101\n",
      "           1       0.47      0.51      0.49       197\n",
      "           2       0.51      0.67      0.58       193\n",
      "           3       0.96      0.84      0.90       161\n",
      "\n",
      "    accuracy                           0.58       652\n",
      "   macro avg       0.55      0.53      0.53       652\n",
      "weighted avg       0.57      0.58      0.56       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Stochastic Gradient Descent (PCA)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "sgd_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('sgd', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42))\n",
    "])\n",
    "\n",
    "sgd_pipeline.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = sgd_pipeline.predict(X_test_pca)\n",
    "print(\"SGD Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8a320818-6f62-4eba-8854-64403257d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Accuracy metrics for SGD with PCA are too low to pursue further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d78ae4c3-d35a-4b0f-b132-8164dbbb828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Accuracy: 0.8052147239263804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.12      0.20       101\n",
      "           1       0.69      0.96      0.80       197\n",
      "           2       0.91      0.86      0.88       193\n",
      "           3       0.91      0.98      0.95       161\n",
      "\n",
      "    accuracy                           0.81       652\n",
      "   macro avg       0.77      0.73      0.71       652\n",
      "weighted avg       0.79      0.81      0.77       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Gradient Boost (PCA)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    loss='log_loss',        # cross-entropy loss\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('gb', GradientBoostingClassifier(loss='log_loss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipeline.fit(X_train_pca, y_train)\n",
    "y_pred = gb_pipeline.predict(X_test_pca)\n",
    "\n",
    "print(\"GB Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "106a4991-a0bc-45ee-8d3f-d4e42ba0e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "536afc7c-efa7-4bb2-a17e-a39cd64882da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2604, 50176)\n",
      "(652, 50176)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "794b5c9f-d12a-42bb-8df6-7af75c72ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Accuracy: 0.8052147239263804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.08      0.14       101\n",
      "           1       0.69      0.95      0.80       197\n",
      "           2       0.88      0.90      0.89       193\n",
      "           3       0.94      0.97      0.95       161\n",
      "\n",
      "    accuracy                           0.81       652\n",
      "   macro avg       0.75      0.72      0.69       652\n",
      "weighted avg       0.77      0.81      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Gradient Boost (full dimensionality)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('gb', GradientBoostingClassifier(loss='log_loss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "y_pred = gb_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"GB Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b034ae23-5d91-4e89-8e0e-eaf9e8308101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [17:10:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8006134969325154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.13      0.22       101\n",
      "           1       0.68      0.95      0.79       197\n",
      "           2       0.86      0.88      0.87       193\n",
      "           3       0.93      0.95      0.94       161\n",
      "\n",
      "    accuracy                           0.80       652\n",
      "   macro avg       0.81      0.73      0.71       652\n",
      "weighted avg       0.81      0.80      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: XG Boost (PCA)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        objective='multi:softmax',  \n",
    "        num_class = 4,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        verbosity=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train_pca, y_train)\n",
    "\n",
    "\n",
    "y_pred = xgb_pipeline.predict(X_test_pca)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a35bad72-6619-4c7c-84eb-b4f7a8b20d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [17:11:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.803680981595092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.10      0.17       101\n",
      "           1       0.68      0.95      0.79       197\n",
      "           2       0.89      0.90      0.89       193\n",
      "           3       0.93      0.95      0.94       161\n",
      "\n",
      "    accuracy                           0.80       652\n",
      "   macro avg       0.77      0.73      0.70       652\n",
      "weighted avg       0.79      0.80      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: XG Boost (full dimensionality)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        objective='multi:softmax',  \n",
    "        num_class = 4,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        verbosity=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = xgb_pipeline.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5a0027bc-60f9-4b2e-bee2-8e39f4859d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORKS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "480ec528-4d1a-4fcf-b450-b820508b5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5559\n",
      "Epoch 2 Loss: 0.4445\n",
      "Epoch 3 Loss: 0.6343\n",
      "Epoch 4 Loss: 0.2114\n",
      "Epoch 5 Loss: 0.0895\n",
      "Epoch 6 Loss: 0.0576\n",
      "Epoch 7 Loss: 0.2045\n",
      "Epoch 8 Loss: 0.0111\n",
      "Epoch 9 Loss: 0.1132\n",
      "Epoch 10 Loss: 0.0031\n",
      "Torch Accuracy: 0.7791411042944786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.26      0.36       112\n",
      "           1       0.71      0.79      0.75       192\n",
      "           2       0.78      0.90      0.84       193\n",
      "           3       0.92      0.99      0.95       155\n",
      "\n",
      "    accuracy                           0.78       652\n",
      "   macro avg       0.75      0.73      0.72       652\n",
      "weighted avg       0.76      0.78      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = MLP(X_train.shape[1], 4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, preds = torch.max(outputs, 1)  # Get predicted class index\n",
    "\n",
    "y_pred = preds.numpy()\n",
    "y_true = y_test_tensor.numpy()\n",
    "\n",
    "print(\"Torch Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "504d0f25-0bfb-436a-b8bd-f103ccd3f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 - 2s - 43ms/step - accuracy: 0.6748 - loss: 3.9458 - val_accuracy: 0.7356 - val_loss: 2.9300\n",
      "Epoch 2/20\n",
      "37/37 - 1s - 29ms/step - accuracy: 0.8344 - loss: 1.4235 - val_accuracy: 0.7088 - val_loss: 3.5991\n",
      "Epoch 3/20\n",
      "37/37 - 1s - 29ms/step - accuracy: 0.8903 - loss: 0.7532 - val_accuracy: 0.7663 - val_loss: 3.1053\n",
      "Epoch 4/20\n",
      "37/37 - 1s - 29ms/step - accuracy: 0.9155 - loss: 0.6040 - val_accuracy: 0.7586 - val_loss: 3.6856\n",
      "Epoch 5/20\n",
      "37/37 - 1s - 29ms/step - accuracy: 0.9287 - loss: 0.4022 - val_accuracy: 0.7854 - val_loss: 3.5545\n",
      "Epoch 6/20\n",
      "37/37 - 1s - 30ms/step - accuracy: 0.9424 - loss: 0.4004 - val_accuracy: 0.7548 - val_loss: 3.8956\n",
      "Epoch 7/20\n",
      "37/37 - 1s - 29ms/step - accuracy: 0.9548 - loss: 0.2821 - val_accuracy: 0.7739 - val_loss: 4.4617\n",
      "Epoch 8/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9560 - loss: 0.3144 - val_accuracy: 0.7510 - val_loss: 4.3044\n",
      "Epoch 9/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9535 - loss: 0.3961 - val_accuracy: 0.7739 - val_loss: 4.0781\n",
      "Epoch 10/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9629 - loss: 0.2971 - val_accuracy: 0.7854 - val_loss: 4.6680\n",
      "Epoch 11/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9629 - loss: 0.2129 - val_accuracy: 0.7663 - val_loss: 5.3243\n",
      "Epoch 12/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9663 - loss: 0.2181 - val_accuracy: 0.7854 - val_loss: 4.9317\n",
      "Epoch 13/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9688 - loss: 0.2389 - val_accuracy: 0.7931 - val_loss: 6.3139\n",
      "Epoch 14/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9710 - loss: 0.1912 - val_accuracy: 0.7701 - val_loss: 5.4795\n",
      "Epoch 15/20\n",
      "37/37 - 1s - 30ms/step - accuracy: 0.9731 - loss: 0.1435 - val_accuracy: 0.7778 - val_loss: 5.6434\n",
      "Epoch 16/20\n",
      "37/37 - 1s - 29ms/step - accuracy: 0.9778 - loss: 0.1295 - val_accuracy: 0.7739 - val_loss: 5.7104\n",
      "Epoch 17/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9731 - loss: 0.1782 - val_accuracy: 0.7739 - val_loss: 6.2925\n",
      "Epoch 18/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9795 - loss: 0.2065 - val_accuracy: 0.7625 - val_loss: 6.2045\n",
      "Epoch 19/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9791 - loss: 0.1539 - val_accuracy: 0.7586 - val_loss: 6.9699\n",
      "Epoch 20/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9714 - loss: 0.2604 - val_accuracy: 0.7625 - val_loss: 6.8829\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 4.4574\n",
      "Tensorflow Accuracy: 0.7929447889328003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.26      0.36       112\n",
      "           1       0.71      0.79      0.75       192\n",
      "           2       0.78      0.90      0.84       193\n",
      "           3       0.92      0.99      0.95       155\n",
      "\n",
      "    accuracy                           0.78       652\n",
      "   macro avg       0.75      0.73      0.72       652\n",
      "weighted avg       0.76      0.78      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(set(y)), activation='softmax')  # for multiclass\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # if y is integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Tensorflow Accuracy:\", test_acc)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "dc32d579-c73e-4498-93b6-f2173a8bc087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.9496\n",
      "Epoch 2 Loss: 0.3849\n",
      "Epoch 3 Loss: 0.2210\n",
      "Epoch 4 Loss: 0.1568\n",
      "Epoch 5 Loss: 0.0960\n",
      "Epoch 6 Loss: 0.0813\n",
      "Epoch 7 Loss: 0.0603\n",
      "Epoch 8 Loss: 0.0831\n",
      "Epoch 9 Loss: 0.1061\n",
      "Epoch 10 Loss: 0.0764\n"
     ]
    }
   ],
   "source": [
    "# MODEL: PyTorch (Part 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], num_classes=len(set(y)))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c624d76c-8d1f-4eda-aedc-9f6464f13f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.0859, Accuracy = 0.9747\n",
      "Epoch 2: Loss = 0.0976, Accuracy = 0.9731\n",
      "Epoch 3: Loss = 0.0882, Accuracy = 0.9739\n",
      "Epoch 4: Loss = 0.0803, Accuracy = 0.9823\n",
      "Epoch 5: Loss = 0.0764, Accuracy = 0.9796\n",
      "Epoch 6: Loss = 0.0430, Accuracy = 0.9831\n",
      "Epoch 7: Loss = 0.0648, Accuracy = 0.9789\n",
      "Epoch 8: Loss = 0.0456, Accuracy = 0.9858\n",
      "Epoch 9: Loss = 0.0364, Accuracy = 0.9919\n",
      "Epoch 10: Loss = 0.0270, Accuracy = 0.9892\n",
      "Test Accuracy: 0.7975460122699386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.24      0.36       114\n",
      "           1       0.68      0.89      0.77       183\n",
      "           2       0.83      0.89      0.86       196\n",
      "           3       0.95      0.98      0.96       159\n",
      "\n",
      "    accuracy                           0.80       652\n",
      "   macro avg       0.79      0.75      0.74       652\n",
      "weighted avg       0.79      0.80      0.77       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: PyTorch (Part 2)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy tracking\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        outputs = model(xb)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(yb.numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "e19c9829-e8ca-4e6b-b9e8-dd1c153d432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6.10375590\n",
      "Iteration 2, loss = 4.26093398\n",
      "Iteration 3, loss = 1.18470432\n",
      "Iteration 4, loss = 0.41197161\n",
      "Iteration 5, loss = 0.25173075\n",
      "Iteration 6, loss = 0.10563205\n",
      "Iteration 7, loss = 0.04561601\n",
      "Iteration 8, loss = 0.02024590\n",
      "Iteration 9, loss = 0.00705918\n",
      "Iteration 10, loss = 0.00192119\n",
      "Iteration 11, loss = 0.00111573\n",
      "Iteration 12, loss = 0.00103905\n",
      "Iteration 13, loss = 0.00097114\n",
      "Iteration 14, loss = 0.00094106\n",
      "Iteration 15, loss = 0.00092025\n",
      "Iteration 16, loss = 0.00089787\n",
      "Iteration 17, loss = 0.00088016\n",
      "Iteration 18, loss = 0.00086720\n",
      "Iteration 19, loss = 0.00085398\n",
      "Iteration 20, loss = 0.00084220\n",
      "Iteration 21, loss = 0.00083073\n",
      "Iteration 22, loss = 0.00082105\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.7714723926380368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.34      0.41       114\n",
      "           1       0.71      0.77      0.74       183\n",
      "           2       0.80      0.85      0.82       196\n",
      "           3       0.92      0.99      0.95       159\n",
      "\n",
      "    accuracy                           0.77       652\n",
      "   macro avg       0.74      0.74      0.73       652\n",
      "weighted avg       0.75      0.77      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: MLP Classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_train)\n",
    "X_te = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=100,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "mlp.fit(X_tr, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_te)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c9477d2b-24ec-4b18-8638-f366d10e55b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.00155756, -0.00155756, -0.00155756],\n",
       "         [-0.00124988, -0.00124988, -0.00124988],\n",
       "         [-0.00123947, -0.00123947, -0.00123947],\n",
       "         ...,\n",
       "         [-0.00146085, -0.00146085, -0.00146085],\n",
       "         [-0.00147113, -0.00147113, -0.00147113],\n",
       "         [-0.00149912, -0.00149912, -0.00149912]],\n",
       "\n",
       "        [[-0.0013257 , -0.0013257 , -0.0013257 ],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00122976, -0.00122976, -0.00122976],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00143114, -0.00143114, -0.00143114],\n",
       "         [-0.00152065, -0.00152065, -0.00152065]],\n",
       "\n",
       "        [[-0.00095075, -0.00095075, -0.00095075],\n",
       "         [-0.00146372, -0.00146372, -0.00146372],\n",
       "         [-0.00140128, -0.00140128, -0.00140128],\n",
       "         ...,\n",
       "         [-0.00142726, -0.00142726, -0.00142726],\n",
       "         [-0.00136863, -0.00136863, -0.00136863],\n",
       "         [-0.00148946, -0.00148946, -0.00148946]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00148081, -0.00148081, -0.00148081],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00117677, -0.00117677, -0.00117677],\n",
       "         [-0.000966  , -0.000966  , -0.000966  ],\n",
       "         [-0.00067981, -0.00067981, -0.00067981]],\n",
       "\n",
       "        [[-0.00173635, -0.00173635, -0.00173635],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00130132, -0.00130132, -0.00130132],\n",
       "         [-0.00123925, -0.00123925, -0.00123925],\n",
       "         [-0.00112128, -0.00112128, -0.00112128]],\n",
       "\n",
       "        [[-0.00195696, -0.00195696, -0.00195696],\n",
       "         [-0.00181354, -0.00181354, -0.00181354],\n",
       "         [-0.00168159, -0.00168159, -0.00168159],\n",
       "         ...,\n",
       "         [-0.00138475, -0.00138475, -0.00138475],\n",
       "         [-0.00122131, -0.00122131, -0.00122131],\n",
       "         [-0.00123692, -0.00123692, -0.00123692]]],\n",
       "\n",
       "\n",
       "       [[[-0.00163751, -0.00163751, -0.00163751],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [-0.00146085, -0.00146085, -0.00146085],\n",
       "         [-0.00147113, -0.00147113, -0.00147113],\n",
       "         [-0.00149912, -0.00149912, -0.00149912]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00150551, -0.00150551, -0.00150551],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00143114, -0.00143114, -0.00143114],\n",
       "         [-0.00152065, -0.00152065, -0.00152065]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00137977, -0.00137977, -0.00137977],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.00145591, -0.00145591, -0.00145591],\n",
       "         [-0.00148946, -0.00148946, -0.00148946]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00154474, -0.00154474, -0.00154474],\n",
       "         [-0.00139708, -0.00139708, -0.00139708],\n",
       "         [-0.00145962, -0.00145962, -0.00145962],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00165746, -0.00165746, -0.00165746],\n",
       "         [-0.00146299, -0.00146299, -0.00146299],\n",
       "         [-0.00140749, -0.00140749, -0.00140749],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00139024, -0.00139024, -0.00139024]],\n",
       "\n",
       "        [[-0.00173699, -0.00173699, -0.00173699],\n",
       "         [ 0.00254668,  0.00254668,  0.00254668],\n",
       "         [-0.00160359, -0.00160359, -0.00160359],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00141473, -0.00141473, -0.00141473]]],\n",
       "\n",
       "\n",
       "       [[[-0.00171746, -0.00171746, -0.00171746],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [ 0.0001716 ,  0.0001716 ,  0.0001716 ],\n",
       "         [-0.00112452, -0.00112452, -0.00112452],\n",
       "         [-0.00106619, -0.00106619, -0.00106619]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [ 0.00927476,  0.00927476,  0.00927476],\n",
       "         [-0.00072337, -0.00072337, -0.00072337],\n",
       "         [-0.00117654, -0.00117654, -0.00117654]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00154767, -0.00154767, -0.00154767],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [ 0.00730498,  0.00730498,  0.00730498],\n",
       "         [-0.00084491, -0.00084491, -0.00084491],\n",
       "         [-0.00105835, -0.00105835, -0.00105835]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00148081, -0.00148081, -0.00148081],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00080459, -0.00080459, -0.00080459],\n",
       "         [-0.00077516, -0.00077516, -0.00077516],\n",
       "         [-0.00096698, -0.00096698, -0.00096698]],\n",
       "\n",
       "        [[-0.00173635, -0.00173635, -0.00173635],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00121293, -0.00121293, -0.00121293],\n",
       "         [-0.0013282 , -0.0013282 , -0.0013282 ],\n",
       "         [-0.00121093, -0.00121093, -0.00121093]],\n",
       "\n",
       "        [[-0.00195696, -0.00195696, -0.00195696],\n",
       "         [-0.00181354, -0.00181354, -0.00181354],\n",
       "         [-0.00168159, -0.00168159, -0.00168159],\n",
       "         ...,\n",
       "         [-0.00064843, -0.00064843, -0.00064843],\n",
       "         [-0.00122131, -0.00122131, -0.00122131],\n",
       "         [-0.00097021, -0.00097021, -0.00097021]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.00204016,  0.00204016,  0.00204016],\n",
       "         [-0.00099917, -0.00099917, -0.00099917],\n",
       "         [-0.00132186, -0.00132186, -0.00132186],\n",
       "         ...,\n",
       "         [-0.00154676, -0.00154676, -0.00154676],\n",
       "         [-0.00155778, -0.00155778, -0.00155778],\n",
       "         [-0.0015857 , -0.0015857 , -0.0015857 ]],\n",
       "\n",
       "        [[ 0.00787475,  0.00787475,  0.00787475],\n",
       "         [-0.00091721, -0.00091721, -0.00091721],\n",
       "         [-0.00147948, -0.00147948, -0.00147948],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00160668, -0.00160668, -0.00160668]],\n",
       "\n",
       "        [[ 0.00109804,  0.00109804,  0.00109804],\n",
       "         [-0.0004563 , -0.0004563 , -0.0004563 ],\n",
       "         [-0.00081245, -0.00081245, -0.00081245],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00139708, -0.00139708, -0.00139708],\n",
       "         [-0.00145962, -0.00145962, -0.00145962],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00149966, -0.00149966, -0.00149966],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00139024, -0.00139024, -0.00139024]],\n",
       "\n",
       "        [[-0.00181032, -0.00181032, -0.00181032],\n",
       "         [-0.00173704, -0.00173704, -0.00173704],\n",
       "         [-0.00160359, -0.00160359, -0.00160359],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00141473, -0.00141473, -0.00141473]]],\n",
       "\n",
       "\n",
       "       [[[-0.00171746, -0.00171746, -0.00171746],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [-0.00154676, -0.00154676, -0.00154676],\n",
       "         [-0.00155778, -0.00155778, -0.00155778],\n",
       "         [-0.0015857 , -0.0015857 , -0.0015857 ]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00160668, -0.00160668, -0.00160668]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00154767, -0.00154767, -0.00154767],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00148081, -0.00148081, -0.00148081],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00173635, -0.00173635, -0.00173635],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00130058, -0.00130058, -0.00130058]],\n",
       "\n",
       "        [[-0.00195696, -0.00195696, -0.00195696],\n",
       "         [-0.00181354, -0.00181354, -0.00181354],\n",
       "         [-0.00168159, -0.00168159, -0.00168159],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00132583, -0.00132583, -0.00132583]]],\n",
       "\n",
       "\n",
       "       [[[-0.00171746, -0.00171746, -0.00171746],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [-0.00154676, -0.00154676, -0.00154676],\n",
       "         [-0.00155778, -0.00155778, -0.00155778],\n",
       "         [-0.0015857 , -0.0015857 , -0.0015857 ]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00160668, -0.00160668, -0.00160668]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00154767, -0.00154767, -0.00154767],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00148081, -0.00148081, -0.00148081],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00173635, -0.00173635, -0.00173635],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00139024, -0.00139024, -0.00139024]],\n",
       "\n",
       "        [[-0.00195696, -0.00195696, -0.00195696],\n",
       "         [-0.00181354, -0.00181354, -0.00181354],\n",
       "         [-0.00168159, -0.00168159, -0.00168159],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00141473, -0.00141473, -0.00141473]]]], dtype=float32)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: RESNET 50 (Part 1)\n",
    "\n",
    "X_images = X.reshape(-1, 224, 224, 1)\n",
    "\n",
    "X_images = X_images.astype('float32') / 255.0\n",
    "y_labels = y  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).shuffle(1000)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n",
    "tru = np.repeat(X_images, 3, axis=-1)\n",
    "\n",
    "tru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e19cb749-9f11-44ba-b1b0-1aaf527da3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: RESNET 50 (Part 2)\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "X_images = X.reshape(-1, 224, 224, 1)\n",
    "\n",
    "X_rgb = np.repeat(X_images, 3, axis=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rgb, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).shuffle(1000)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "7e274fa5-7bf1-4ccd-9663-b91f4e2dc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: RESNET 50 (Part 3)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze pretrained layers\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(len(np.unique(y)), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1a0eebdb-ee2c-4bde-9119-8f9c871e20fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (3256, 224, 224, 3)\n",
      "Epoch 1/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 614ms/step - accuracy: 0.9909 - loss: 0.0301 - val_accuracy: 0.9601 - val_loss: 0.1184\n",
      "Epoch 2/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 612ms/step - accuracy: 0.9897 - loss: 0.0302 - val_accuracy: 0.9617 - val_loss: 0.1167\n",
      "Epoch 3/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 614ms/step - accuracy: 0.9962 - loss: 0.0223 - val_accuracy: 0.9617 - val_loss: 0.1154\n",
      "Epoch 4/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 629ms/step - accuracy: 0.9919 - loss: 0.0255 - val_accuracy: 0.9479 - val_loss: 0.1592\n",
      "Epoch 5/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 635ms/step - accuracy: 0.9849 - loss: 0.0408 - val_accuracy: 0.9617 - val_loss: 0.1165\n",
      "Epoch 6/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 617ms/step - accuracy: 0.9940 - loss: 0.0198 - val_accuracy: 0.9540 - val_loss: 0.1422\n",
      "Epoch 7/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 612ms/step - accuracy: 0.9979 - loss: 0.0152 - val_accuracy: 0.9448 - val_loss: 0.1456\n",
      "Epoch 8/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 610ms/step - accuracy: 0.9967 - loss: 0.0129 - val_accuracy: 0.9632 - val_loss: 0.1267\n",
      "Epoch 9/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 612ms/step - accuracy: 0.9986 - loss: 0.0098 - val_accuracy: 0.9571 - val_loss: 0.1287\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step\n",
      "Accuracy: 0.9570552147239264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90       114\n",
      "           1       0.93      0.96      0.95       183\n",
      "           2       0.98      0.97      0.97       196\n",
      "           3       0.97      1.00      0.98       159\n",
      "\n",
      "    accuracy                           0.96       652\n",
      "   macro avg       0.96      0.95      0.95       652\n",
      "weighted avg       0.96      0.96      0.96       652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 17:56:39.045133: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# MODEL: RESNET 50 (Part 4)\n",
    "\n",
    "print(\"Input shape:\", X_rgb.shape)\n",
    "\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=9)\n",
    "\n",
    "\n",
    "y_probs = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_probs, axis=1)\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e256c4-6991-42e8-a912-ae7b72df7f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
