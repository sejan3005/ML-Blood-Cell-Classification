{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9b36b1-9aaa-4ee7-bb15-7a0f0091feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PREPARATION ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c79132f9-0449-466e-a2c0-48b5a4e4ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Initial Libraries\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2b05ae-f383-407d-ac71-4c3a9915bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import known modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e958a7a2-374d-47d3-a404-fb036b593da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca31ff9-e425-47ca-93cf-bebcfb0c9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff4afce7-0b20-4899-9e2d-4fa30910c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d41afb-a66b-44e0-b521-45d867d37c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read initial built CSV to notebook\n",
    "\n",
    "df = pd.read_csv('Diagnosis_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfb8cc67-a62d-4ff9-bcae-b1fb1ab2f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel50168</th>\n",
       "      <th>pixel50169</th>\n",
       "      <th>pixel50170</th>\n",
       "      <th>pixel50171</th>\n",
       "      <th>pixel50172</th>\n",
       "      <th>pixel50173</th>\n",
       "      <th>pixel50174</th>\n",
       "      <th>pixel50175</th>\n",
       "      <th>pixel50176</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.454902</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3256 rows × 50177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.007843  0.003922  0.003922  0.003922  0.000000  0.003922  0.003922   \n",
       "2     0.450980  0.027451  0.007843  0.003922  0.015686  0.015686  0.003922   \n",
       "3     0.007843  0.011765  0.121569  0.047059  0.337255  0.435294  0.109804   \n",
       "4     0.015686  0.015686  0.007843  0.015686  0.007843  0.450980  0.380392   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3251  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3252  0.003922  0.003922  0.007843  0.003922  0.003922  0.007843  0.003922   \n",
       "3253  0.003922  0.011765  0.011765  0.007843  0.007843  0.007843  0.003922   \n",
       "3254  0.380392  0.454902  0.137255  0.007843  0.015686  0.011765  0.000000   \n",
       "3255  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        pixel8    pixel9   pixel10  ...  pixel50168  pixel50169  pixel50170  \\\n",
       "0     0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "1     0.003922  0.003922  0.003922  ...    0.011765    0.015686    0.007843   \n",
       "2     0.007843  0.007843  0.003922  ...    0.498039    0.027451    0.011765   \n",
       "3     0.450980  0.082353  0.047059  ...    0.003922    0.019608    0.007843   \n",
       "4     0.360784  0.450980  0.070588  ...    0.015686    0.007843    0.003922   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "3251  0.000000  0.000000  0.000000  ...    0.003922    0.000000    0.000000   \n",
       "3252  0.011765  0.007843  0.003922  ...    0.000000    0.000000    0.000000   \n",
       "3253  0.003922  0.003922  0.007843  ...    0.000000    0.000000    0.000000   \n",
       "3254  0.003922  0.000000  0.007843  ...    0.000000    0.000000    0.000000   \n",
       "3255  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "\n",
       "      pixel50171  pixel50172  pixel50173  pixel50174  pixel50175  pixel50176  \\\n",
       "0       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1       0.000000    0.007843    0.003922    0.003922    0.011765    0.011765   \n",
       "2       0.011765    0.011765    0.007843    0.003922    0.011765    0.011765   \n",
       "3       0.015686    0.003922    0.031373    0.027451    0.054902    0.490196   \n",
       "4       0.003922    0.007843    0.011765    0.003922    0.003922    0.011765   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3251    0.003922    0.003922    0.000000    0.000000    0.000000    0.000000   \n",
       "3252    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3253    0.023529    0.352941    0.450980    0.482353    0.035294    0.023529   \n",
       "3254    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3255    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "      diagnosis  \n",
       "0        benign  \n",
       "1        benign  \n",
       "2        benign  \n",
       "3        benign  \n",
       "4        benign  \n",
       "...         ...  \n",
       "3251        pro  \n",
       "3252        pro  \n",
       "3253        pro  \n",
       "3254        pro  \n",
       "3255        pro  \n",
       "\n",
       "[3256 rows x 50177 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking dataframe shape and content\n",
    "\n",
    "df2 = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4718c3c0-bbfb-4a0b-9490-380c30dc3fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel50168</th>\n",
       "      <th>pixel50169</th>\n",
       "      <th>pixel50170</th>\n",
       "      <th>pixel50171</th>\n",
       "      <th>pixel50172</th>\n",
       "      <th>pixel50173</th>\n",
       "      <th>pixel50174</th>\n",
       "      <th>pixel50175</th>\n",
       "      <th>pixel50176</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419608</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3256 rows × 50177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel1    pixel2    pixel3    pixel4    pixel5    pixel6    pixel7  \\\n",
       "2068  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1723  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3090  0.007843  0.000000  0.003922  0.000000  0.003922  0.003922  0.000000   \n",
       "2283  0.003922  0.003922  0.007843  0.003922  0.000000  0.000000  0.000000   \n",
       "1090  0.003922  0.000000  0.007843  0.000000  0.000000  0.007843  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1098  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2581  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2798  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2881  0.125490  0.611765  0.588235  0.584314  0.576471  0.560784  0.560784   \n",
       "493   0.176471  0.058824  0.015686  0.003922  0.007843  0.011765  0.000000   \n",
       "\n",
       "        pixel8    pixel9   pixel10  ...  pixel50168  pixel50169  pixel50170  \\\n",
       "2068  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "1723  0.000000  0.003922  0.003922  ...    0.000000    0.000000    0.000000   \n",
       "3090  0.007843  0.007843  0.003922  ...    0.050980    0.023529    0.019608   \n",
       "2283  0.003922  0.007843  0.003922  ...    0.627451    0.603922    0.607843   \n",
       "1090  0.003922  0.000000  0.000000  ...    0.007843    0.003922    0.003922   \n",
       "...        ...       ...       ...  ...         ...         ...         ...   \n",
       "1098  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "2581  0.000000  0.000000  0.000000  ...    0.419608    0.490196    0.090196   \n",
       "2798  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "2881  0.568627  0.568627  0.556863  ...    0.003922    0.003922    0.000000   \n",
       "493   0.003922  0.003922  0.007843  ...    0.003922    0.011765    0.007843   \n",
       "\n",
       "      pixel50171  pixel50172  pixel50173  pixel50174  pixel50175  pixel50176  \\\n",
       "2068    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1723    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "3090    0.290196    0.058824    0.239216    0.141176    0.007843    0.003922   \n",
       "2283    0.607843    0.592157    0.588235    0.584314    0.592157    0.564706   \n",
       "1090    0.000000    0.007843    0.011765    0.007843    0.003922    0.003922   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1098    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2581    0.027451    0.035294    0.007843    0.019608    0.015686    0.015686   \n",
       "2798    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2881    0.003922    0.003922    0.003922    0.003922    0.003922    0.003922   \n",
       "493     0.015686    0.007843    0.031373    0.588235    0.576471    0.541176   \n",
       "\n",
       "      diagnosis  \n",
       "2068        pre  \n",
       "1723        pre  \n",
       "3090        pro  \n",
       "2283        pre  \n",
       "1090      early  \n",
       "...         ...  \n",
       "1098      early  \n",
       "2581        pro  \n",
       "2798        pro  \n",
       "2881        pro  \n",
       "493      benign  \n",
       "\n",
       "[3256 rows x 50177 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly shuffle instances within the dataframe\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df2)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee980b1-5983-45a4-8384-b1e6bb61a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL GENERATION AND EVALUATION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fb07a4c-6dd8-485b-881a-ae3a3fd73b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC MODEL METHODS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b053fd23-a9cc-45e7-8cb2-38b386240635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6595\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df.drop(\"diagnosis\", axis=1)  # Feature matrix (all pixel values)\n",
    "y = df[\"diagnosis\"]  \n",
    "\n",
    "y_array = np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = one_hot_encoder.fit_transform(y_array)\n",
    "\n",
    "tru = X\n",
    "tru['Benign'] = y_encoded[:,0]\n",
    "tru['Early'] = y_encoded[:,1]\n",
    "tru['Pre'] = y_encoded[:,2]\n",
    "tru['Pro'] = y_encoded[:,3]\n",
    "\n",
    "\n",
    "X = tru.drop(columns=['Benign', 'Early', 'Pre', 'Pro'])\n",
    "y = tru[['Benign', 'Early', 'Pre', 'Pro']]\n",
    "\n",
    "y = np.argmax(y.values, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_model = LogisticRegression(max_iter = 25000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6dc64d-6b24-42cc-a1d9-125fe6079b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5368098159509203\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Decision Tree\n",
    "\n",
    "from sklearn import tree\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X = df.drop(columns = \"diagnosis\")\n",
    "y_label = df[\"diagnosis\"]\n",
    "\n",
    "one_hot_y = pd.get_dummies(y_label,dtype=float)\n",
    "\n",
    "one_hot_y_array = np.array(one_hot_y)\n",
    "X_array = np.array(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, one_hot_y_array, test_size=0.2, random_state=42,)\n",
    "X_train_sparse = csr_matrix(X_train)\n",
    "\n",
    "tree_classifier = tree.DecisionTreeClassifier(random_state=42,min_samples_split=10,max_depth=25,min_samples_leaf=5, criterion=\"entropy\", )\n",
    "\n",
    "tree_model = tree_classifier.fit(X_train_sparse,y_train)\n",
    "y_hat = tree_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e30c4f-9c93-499f-b5ed-9badea6c79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4325153374233129\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30c8490f-bf89-45d7-a0f9-170c297eb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6579754601226994\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "y = tru[['Benign', 'Early', 'Pre', 'Pro']]\n",
    "y = np.argmax(y.values, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = SVC(kernel='linear') \n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "946ef571-8960-4376-b4c8-9dfb24739a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOOSTING MODEL METHODS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59c09040-0b03-40f6-b371-b67e8aff2031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dimensions: 1126\n"
     ]
    }
   ],
   "source": [
    "# Reducing size to create computational feasibility\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Keep enough components to preserve 95% of variance\n",
    "pca = PCA(n_components=0.95, svd_solver='full')\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"Reduced dimensions:\", X_train_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0379a227-dd20-4f6e-a56f-8d9b22735bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2604, 1126)\n",
      "(652, 1126)\n"
     ]
    }
   ],
   "source": [
    "# Validating image array shape\n",
    "\n",
    "print(X_train_pca.shape)\n",
    "\n",
    "print(X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fbf588a-c7c4-4b23-aaaa-1e1ff993e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy: 0.5736196319018405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.17      0.23       101\n",
      "           1       0.46      0.58      0.51       197\n",
      "           2       0.52      0.62      0.56       193\n",
      "           3       0.98      0.77      0.86       161\n",
      "\n",
      "    accuracy                           0.57       652\n",
      "   macro avg       0.58      0.53      0.54       652\n",
      "weighted avg       0.59      0.57      0.57       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Stochastic Gradient Descent (PCA)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "sgd_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('sgd', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42))\n",
    "])\n",
    "\n",
    "sgd_pipeline.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = sgd_pipeline.predict(X_test_pca)\n",
    "print(\"SGD Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a320818-6f62-4eba-8854-64403257d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Accuracy metrics for SGD with PCA are too low to pursue further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d78ae4c3-d35a-4b0f-b132-8164dbbb828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Accuracy: 0.7914110429447853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.15      0.23       101\n",
      "           1       0.68      0.91      0.78       197\n",
      "           2       0.90      0.87      0.89       193\n",
      "           3       0.90      0.95      0.92       161\n",
      "\n",
      "    accuracy                           0.79       652\n",
      "   macro avg       0.74      0.72      0.70       652\n",
      "weighted avg       0.77      0.79      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Gradient Boost (PCA)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    loss='log_loss',        # cross-entropy loss\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('gb', GradientBoostingClassifier(loss='log_loss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipeline.fit(X_train_pca, y_train)\n",
    "y_pred = gb_pipeline.predict(X_test_pca)\n",
    "\n",
    "print(\"GB Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "794b5c9f-d12a-42bb-8df6-7af75c72ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Accuracy: 0.8174846625766872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.24      0.35       101\n",
      "           1       0.69      0.91      0.79       197\n",
      "           2       0.89      0.92      0.90       193\n",
      "           3       0.97      0.95      0.96       161\n",
      "\n",
      "    accuracy                           0.82       652\n",
      "   macro avg       0.80      0.75      0.75       652\n",
      "weighted avg       0.81      0.82      0.80       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Gradient Boost (full dimensionality)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('gb', GradientBoostingClassifier(loss='log_loss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "])\n",
    "\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "y_pred = gb_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"GB Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b034ae23-5d91-4e89-8e0e-eaf9e8308101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:27:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.803680981595092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.11      0.18       101\n",
      "           1       0.69      0.94      0.79       197\n",
      "           2       0.89      0.89      0.89       193\n",
      "           3       0.93      0.96      0.95       161\n",
      "\n",
      "    accuracy                           0.80       652\n",
      "   macro avg       0.76      0.73      0.70       652\n",
      "weighted avg       0.78      0.80      0.77       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: XG Boost (PCA)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        objective='multi:softmax',  \n",
    "        num_class = 4,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        verbosity=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train_pca, y_train)\n",
    "\n",
    "\n",
    "y_pred = xgb_pipeline.predict(X_test_pca)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a35bad72-6619-4c7c-84eb-b4f7a8b20d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:28:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8098159509202454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.21      0.31       101\n",
      "           1       0.70      0.91      0.79       197\n",
      "           2       0.87      0.92      0.89       193\n",
      "           3       0.97      0.94      0.95       161\n",
      "\n",
      "    accuracy                           0.81       652\n",
      "   macro avg       0.78      0.74      0.74       652\n",
      "weighted avg       0.80      0.81      0.79       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: XG Boost (full dimensionality)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95, svd_solver='full')),\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        objective='multi:softmax',  \n",
    "        num_class = 4,\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        verbosity=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = xgb_pipeline.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a0027bc-60f9-4b2e-bee2-8e39f4859d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORKS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "480ec528-4d1a-4fcf-b450-b820508b5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.4291\n",
      "Epoch 2 Loss: 0.2836\n",
      "Epoch 3 Loss: 0.3388\n",
      "Epoch 4 Loss: 0.0310\n",
      "Epoch 5 Loss: 0.0141\n",
      "Epoch 6 Loss: 0.0317\n",
      "Epoch 7 Loss: 0.4902\n",
      "Epoch 8 Loss: 0.0759\n",
      "Epoch 9 Loss: 0.0573\n",
      "Epoch 10 Loss: 0.0440\n",
      "Torch Accuracy: 0.7960122699386503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.36      0.41        96\n",
      "           1       0.76      0.77      0.77       207\n",
      "           2       0.83      0.88      0.86       199\n",
      "           3       0.96      0.99      0.97       150\n",
      "\n",
      "    accuracy                           0.80       652\n",
      "   macro avg       0.75      0.75      0.75       652\n",
      "weighted avg       0.78      0.80      0.79       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = MLP(X_train.shape[1], 4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, preds = torch.max(outputs, 1)  # Get predicted class index\n",
    "\n",
    "y_pred = preds.numpy()\n",
    "y_true = y_test_tensor.numpy()\n",
    "\n",
    "print(\"Torch Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "504d0f25-0bfb-436a-b8bd-f103ccd3f358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37/37 - 1s - 40ms/step - accuracy: 0.6321 - loss: 3.8856 - val_accuracy: 0.7586 - val_loss: 2.0682\n",
      "Epoch 2/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.8242 - loss: 1.2483 - val_accuracy: 0.7395 - val_loss: 1.9137\n",
      "Epoch 3/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.8865 - loss: 0.6934 - val_accuracy: 0.7625 - val_loss: 2.0585\n",
      "Epoch 4/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9176 - loss: 0.4645 - val_accuracy: 0.7854 - val_loss: 1.9230\n",
      "Epoch 5/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9377 - loss: 0.3829 - val_accuracy: 0.7969 - val_loss: 2.0725\n",
      "Epoch 6/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9334 - loss: 0.3780 - val_accuracy: 0.7893 - val_loss: 2.7002\n",
      "Epoch 7/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9539 - loss: 0.2814 - val_accuracy: 0.7739 - val_loss: 3.0941\n",
      "Epoch 8/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9603 - loss: 0.2514 - val_accuracy: 0.7701 - val_loss: 3.1512\n",
      "Epoch 9/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9535 - loss: 0.2451 - val_accuracy: 0.7931 - val_loss: 3.2031\n",
      "Epoch 10/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9582 - loss: 0.2019 - val_accuracy: 0.7778 - val_loss: 4.1361\n",
      "Epoch 11/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9565 - loss: 0.2599 - val_accuracy: 0.7663 - val_loss: 3.6102\n",
      "Epoch 12/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9637 - loss: 0.2006 - val_accuracy: 0.7701 - val_loss: 3.5324\n",
      "Epoch 13/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9671 - loss: 0.2238 - val_accuracy: 0.8008 - val_loss: 4.3533\n",
      "Epoch 14/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9676 - loss: 0.1986 - val_accuracy: 0.7778 - val_loss: 4.1119\n",
      "Epoch 15/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9748 - loss: 0.1436 - val_accuracy: 0.7854 - val_loss: 4.2141\n",
      "Epoch 16/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9680 - loss: 0.2003 - val_accuracy: 0.8046 - val_loss: 4.3605\n",
      "Epoch 17/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9663 - loss: 0.2025 - val_accuracy: 0.7854 - val_loss: 4.1518\n",
      "Epoch 18/20\n",
      "37/37 - 1s - 28ms/step - accuracy: 0.9774 - loss: 0.1439 - val_accuracy: 0.7816 - val_loss: 4.5261\n",
      "Epoch 19/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9812 - loss: 0.0833 - val_accuracy: 0.7778 - val_loss: 3.9659\n",
      "Epoch 20/20\n",
      "37/37 - 1s - 27ms/step - accuracy: 0.9812 - loss: 0.0928 - val_accuracy: 0.7931 - val_loss: 5.0176\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7810 - loss: 3.4548\n",
      "Tensorflow Accuracy: 0.7668711543083191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.36      0.41        96\n",
      "           1       0.76      0.77      0.77       207\n",
      "           2       0.83      0.88      0.86       199\n",
      "           3       0.96      0.99      0.97       150\n",
      "\n",
      "    accuracy                           0.80       652\n",
      "   macro avg       0.75      0.75      0.75       652\n",
      "weighted avg       0.78      0.80      0.79       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(set(y)), activation='softmax')  # for multiclass\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # if y is integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Tensorflow Accuracy:\", test_acc)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc32d579-c73e-4498-93b6-f2173a8bc087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.0577\n",
      "Epoch 2 Loss: 0.4144\n",
      "Epoch 3 Loss: 0.1991\n",
      "Epoch 4 Loss: 0.1323\n",
      "Epoch 5 Loss: 0.1094\n",
      "Epoch 6 Loss: 0.0804\n",
      "Epoch 7 Loss: 0.0636\n",
      "Epoch 8 Loss: 0.0603\n",
      "Epoch 9 Loss: 0.0710\n",
      "Epoch 10 Loss: 0.0791\n"
     ]
    }
   ],
   "source": [
    "# MODEL: PyTorch (Part 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], num_classes=len(set(y)))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c624d76c-8d1f-4eda-aedc-9f6464f13f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1336, Accuracy = 0.9674\n",
      "Epoch 2: Loss = 0.1150, Accuracy = 0.9647\n",
      "Epoch 3: Loss = 0.0627, Accuracy = 0.9770\n",
      "Epoch 4: Loss = 0.0424, Accuracy = 0.9908\n",
      "Epoch 5: Loss = 0.0413, Accuracy = 0.9866\n",
      "Epoch 6: Loss = 0.0276, Accuracy = 0.9916\n",
      "Epoch 7: Loss = 0.0534, Accuracy = 0.9881\n",
      "Epoch 8: Loss = 0.0443, Accuracy = 0.9854\n",
      "Epoch 9: Loss = 0.0521, Accuracy = 0.9839\n",
      "Epoch 10: Loss = 0.0426, Accuracy = 0.9889\n",
      "Test Accuracy: 0.7699386503067485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.32      0.38       108\n",
      "           1       0.67      0.77      0.72       182\n",
      "           2       0.84      0.85      0.84       194\n",
      "           3       0.95      0.96      0.96       168\n",
      "\n",
      "    accuracy                           0.77       652\n",
      "   macro avg       0.73      0.73      0.72       652\n",
      "weighted avg       0.76      0.77      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: PyTorch (Part 2)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy tracking\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        outputs = model(xb)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(yb.numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e19c9829-e8ca-4e6b-b9e8-dd1c153d432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7.03835696\n",
      "Iteration 2, loss = 2.39773870\n",
      "Iteration 3, loss = 1.30452644\n",
      "Iteration 4, loss = 0.40940326\n",
      "Iteration 5, loss = 0.09966852\n",
      "Iteration 6, loss = 0.02999880\n",
      "Iteration 7, loss = 0.00617935\n",
      "Iteration 8, loss = 0.00170498\n",
      "Iteration 9, loss = 0.00088474\n",
      "Iteration 10, loss = 0.00077634\n",
      "Iteration 11, loss = 0.00074311\n",
      "Iteration 12, loss = 0.00072467\n",
      "Iteration 13, loss = 0.00071244\n",
      "Iteration 14, loss = 0.00070318\n",
      "Iteration 15, loss = 0.00069612\n",
      "Iteration 16, loss = 0.00069025\n",
      "Iteration 17, loss = 0.00068523\n",
      "Iteration 18, loss = 0.00068089\n",
      "Iteration 19, loss = 0.00067635\n",
      "Iteration 20, loss = 0.00067302\n",
      "Iteration 21, loss = 0.00066984\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy: 0.7760736196319018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.37       108\n",
      "           1       0.67      0.79      0.73       182\n",
      "           2       0.81      0.87      0.84       194\n",
      "           3       0.94      0.98      0.96       168\n",
      "\n",
      "    accuracy                           0.78       652\n",
      "   macro avg       0.74      0.73      0.72       652\n",
      "weighted avg       0.76      0.78      0.76       652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODEL: MLP Classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_train)\n",
    "X_te = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=100,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "mlp.fit(X_tr, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_te)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9477d2b-24ec-4b18-8638-f366d10e55b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.00171746, -0.00171746, -0.00171746],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [-0.00154676, -0.00154676, -0.00154676],\n",
       "         [-0.00155778, -0.00155778, -0.00155778],\n",
       "         [-0.0015857 , -0.0015857 , -0.0015857 ]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00160668, -0.00160668, -0.00160668]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00154767, -0.00154767, -0.00154767],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00148081, -0.00148081, -0.00148081],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00173635, -0.00173635, -0.00173635],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00139024, -0.00139024, -0.00139024]],\n",
       "\n",
       "        [[-0.00195696, -0.00195696, -0.00195696],\n",
       "         [-0.00181354, -0.00181354, -0.00181354],\n",
       "         [-0.00168159, -0.00168159, -0.00168159],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00141473, -0.00141473, -0.00141473]]],\n",
       "\n",
       "\n",
       "       [[[-0.00171746, -0.00171746, -0.00171746],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [-0.00103126, -0.00103126, -0.00103126],\n",
       "         [-0.00069125, -0.00069125, -0.00069125],\n",
       "         [-0.00054667, -0.00054667, -0.00054667]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [-0.00100077, -0.00100077, -0.00100077],\n",
       "         [ 0.0090085 ,  0.0090085 ,  0.0090085 ],\n",
       "         [ 0.0088889 ,  0.0088889 ,  0.0088889 ]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00154767, -0.00154767, -0.00154767],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [-0.00092347, -0.00092347, -0.00092347],\n",
       "         [ 0.00901849,  0.00901849,  0.00901849],\n",
       "         [ 0.00954682,  0.00954682,  0.00954682]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00154474, -0.00154474, -0.00154474],\n",
       "         [-0.00139708, -0.00139708, -0.00139708],\n",
       "         [-0.00137993, -0.00137993, -0.00137993],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00173635, -0.00173635, -0.00173635],\n",
       "         [-0.00162495, -0.00162495, -0.00162495],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00139024, -0.00139024, -0.00139024]],\n",
       "\n",
       "        [[-0.00166367, -0.00166367, -0.00166367],\n",
       "         [-0.00173704, -0.00173704, -0.00173704],\n",
       "         [-0.00144759, -0.00144759, -0.00144759],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00141473, -0.00141473, -0.00141473]]],\n",
       "\n",
       "\n",
       "       [[[-0.00155756, -0.00155756, -0.00155756],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00148664, -0.00148664, -0.00148664],\n",
       "         ...,\n",
       "         [-0.00146085, -0.00146085, -0.00146085],\n",
       "         [-0.00138447, -0.00138447, -0.00138447],\n",
       "         [-0.00149912, -0.00149912, -0.00149912]],\n",
       "\n",
       "        [[-0.00156996, -0.00156996, -0.00156996],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00147948, -0.00147948, -0.00147948],\n",
       "         ...,\n",
       "         [-0.00117793, -0.00117793, -0.00117793],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00152065, -0.00152065, -0.00152065]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00146372, -0.00146372, -0.00146372],\n",
       "         [-0.00140128, -0.00140128, -0.00140128],\n",
       "         ...,\n",
       "         [-0.00142726, -0.00142726, -0.00142726],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00148946, -0.00148946, -0.00148946]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0017003 , -0.0017003 , -0.0017003 ],\n",
       "         [-0.00148081, -0.00148081, -0.00148081],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00099068, -0.00099068, -0.00099068],\n",
       "         [-0.000966  , -0.000966  , -0.000966  ],\n",
       "         [-0.00106271, -0.00106271, -0.00106271]],\n",
       "\n",
       "        [[-0.00157856, -0.00157856, -0.00157856],\n",
       "         [-0.00154397, -0.00154397, -0.00154397],\n",
       "         [-0.00156897, -0.00156897, -0.00156897],\n",
       "         ...,\n",
       "         [-0.00094776, -0.00094776, -0.00094776],\n",
       "         [-0.0013282 , -0.0013282 , -0.0013282 ],\n",
       "         [-0.00130058, -0.00130058, -0.00130058]],\n",
       "\n",
       "        [[-0.00166367, -0.00166367, -0.00166367],\n",
       "         [-0.00166055, -0.00166055, -0.00166055],\n",
       "         [-0.00168159, -0.00168159, -0.00168159],\n",
       "         ...,\n",
       "         [ 0.00139691,  0.00139691,  0.00139691],\n",
       "         [-0.00130669, -0.00130669, -0.00130669],\n",
       "         [-0.00132583, -0.00132583, -0.00132583]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.00171746, -0.00171746, -0.00171746],\n",
       "         [-0.00158415, -0.00158415, -0.00158415],\n",
       "         [-0.00156903, -0.00156903, -0.00156903],\n",
       "         ...,\n",
       "         [-0.00154676, -0.00154676, -0.00154676],\n",
       "         [-0.00155778, -0.00155778, -0.00155778],\n",
       "         [-0.0015857 , -0.0015857 , -0.0015857 ]],\n",
       "\n",
       "        [[-0.00165138, -0.00165138, -0.00165138],\n",
       "         [-0.00158955, -0.00158955, -0.00158955],\n",
       "         [-0.00156272, -0.00156272, -0.00156272],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00160668, -0.00160668, -0.00160668]],\n",
       "\n",
       "        [[-0.00160636, -0.00160636, -0.00160636],\n",
       "         [-0.00154767, -0.00154767, -0.00154767],\n",
       "         [-0.0014854 , -0.0014854 , -0.0014854 ],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00092253, -0.00092253, -0.00092253],\n",
       "         [-0.00106215, -0.00106215, -0.00106215],\n",
       "         [-0.00153931, -0.00153931, -0.00153931],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00165746, -0.00165746, -0.00165746],\n",
       "         [-0.00146299, -0.00146299, -0.00146299],\n",
       "         [-0.00140749, -0.00140749, -0.00140749],\n",
       "         ...,\n",
       "         [-0.00138971, -0.00138971, -0.00138971],\n",
       "         [-0.00141715, -0.00141715, -0.00141715],\n",
       "         [-0.00139024, -0.00139024, -0.00139024]],\n",
       "\n",
       "        [[-0.00151702, -0.00151702, -0.00151702],\n",
       "         [-0.00173704, -0.00173704, -0.00173704],\n",
       "         [-0.00144759, -0.00144759, -0.00144759],\n",
       "         ...,\n",
       "         [-0.00154838, -0.00154838, -0.00154838],\n",
       "         [-0.00147746, -0.00147746, -0.00147746],\n",
       "         [-0.00141473, -0.00141473, -0.00141473]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00084092,  0.00084092,  0.00084092],\n",
       "         [ 0.01145246,  0.01145246,  0.01145246],\n",
       "         [ 0.01078948,  0.01078948,  0.01078948],\n",
       "         ...,\n",
       "         [-0.00154676, -0.00154676, -0.00154676],\n",
       "         [-0.00155778, -0.00155778, -0.00155778],\n",
       "         [-0.0015857 , -0.0015857 , -0.0015857 ]],\n",
       "\n",
       "        [[ 0.00022128,  0.00022128,  0.00022128],\n",
       "         [ 0.01051255,  0.01051255,  0.01051255],\n",
       "         [ 0.0109233 ,  0.0109233 ,  0.0109233 ],\n",
       "         ...,\n",
       "         [-0.00153226, -0.00153226, -0.00153226],\n",
       "         [-0.00151961, -0.00151961, -0.00151961],\n",
       "         [-0.00160668, -0.00160668, -0.00160668]],\n",
       "\n",
       "        [[ 0.01011268,  0.01011268,  0.01011268],\n",
       "         [ 0.01154886,  0.01154886,  0.01154886],\n",
       "         [ 0.01113233,  0.01113233,  0.01113233],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00498853,  0.00498853,  0.00498853],\n",
       "         [-0.00131335, -0.00131335, -0.00131335],\n",
       "         [-0.00137993, -0.00137993, -0.00137993],\n",
       "         ...,\n",
       "         [-0.00126981, -0.00126981, -0.00126981],\n",
       "         [-0.00125226, -0.00125226, -0.00125226],\n",
       "         [-0.00125416, -0.00125416, -0.00125416]],\n",
       "\n",
       "        [[-0.00149966, -0.00149966, -0.00149966],\n",
       "         [-0.00146299, -0.00146299, -0.00146299],\n",
       "         [-0.00148823, -0.00148823, -0.00148823],\n",
       "         ...,\n",
       "         [-0.00130132, -0.00130132, -0.00130132],\n",
       "         [-0.0013282 , -0.0013282 , -0.0013282 ],\n",
       "         [-0.00130058, -0.00130058, -0.00130058]],\n",
       "\n",
       "        [[-0.00173699, -0.00173699, -0.00173699],\n",
       "         [-0.00158405, -0.00158405, -0.00158405],\n",
       "         [-0.00160359, -0.00160359, -0.00160359],\n",
       "         ...,\n",
       "         [-0.00146656, -0.00146656, -0.00146656],\n",
       "         [-0.00139208, -0.00139208, -0.00139208],\n",
       "         [-0.00132583, -0.00132583, -0.00132583]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00188026,  0.00188026,  0.00188026],\n",
       "         [-0.00033063, -0.00033063, -0.00033063],\n",
       "         [-0.00123947, -0.00123947, -0.00123947],\n",
       "         ...,\n",
       "         [-0.00137493, -0.00137493, -0.00137493],\n",
       "         [-0.00147113, -0.00147113, -0.00147113],\n",
       "         [-0.00149912, -0.00149912, -0.00149912]],\n",
       "\n",
       "        [[ 0.00795617,  0.00795617,  0.00795617],\n",
       "         [ 0.00908383,  0.00908383,  0.00908383],\n",
       "         [-0.001313  , -0.001313  , -0.001313  ],\n",
       "         ...,\n",
       "         [-0.00144368, -0.00144368, -0.00144368],\n",
       "         [-0.00143114, -0.00143114, -0.00143114],\n",
       "         [-0.00152065, -0.00152065, -0.00152065]],\n",
       "\n",
       "        [[-0.00054099, -0.00054099, -0.00054099],\n",
       "         [-0.00087606, -0.00087606, -0.00087606],\n",
       "         [-0.00131716, -0.00131716, -0.00131716],\n",
       "         ...,\n",
       "         [-0.00159518, -0.00159518, -0.00159518],\n",
       "         [-0.0015432 , -0.0015432 , -0.0015432 ],\n",
       "         [-0.00157568, -0.00157568, -0.00157568]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.00138919, -0.00138919, -0.00138919],\n",
       "         [-0.00139708, -0.00139708, -0.00139708],\n",
       "         [-0.00122056, -0.00122056, -0.00122056],\n",
       "         ...,\n",
       "         [ 0.01129115,  0.01129115,  0.01129115],\n",
       "         [ 0.01210642,  0.01210642,  0.01210642],\n",
       "         [ 0.0130089 ,  0.0130089 ,  0.0130089 ]],\n",
       "\n",
       "        [[-0.00165746, -0.00165746, -0.00165746],\n",
       "         [-0.00138201, -0.00138201, -0.00138201],\n",
       "         [-0.00124601, -0.00124601, -0.00124601],\n",
       "         ...,\n",
       "         [ 0.01063145,  0.01063145,  0.01063145],\n",
       "         [ 0.01156943,  0.01156943,  0.01156943],\n",
       "         [ 0.01062336,  0.01062336,  0.01062336]],\n",
       "\n",
       "        [[-0.00188364, -0.00188364, -0.00188364],\n",
       "         [-0.00166055, -0.00166055, -0.00166055],\n",
       "         [-0.00082359, -0.00082359, -0.00082359],\n",
       "         ...,\n",
       "         [ 0.01072367,  0.01072367,  0.01072367],\n",
       "         [ 0.01107422,  0.01107422,  0.01107422],\n",
       "         [ 0.01085424,  0.01085424,  0.01085424]]]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: RESNET 50 (Part 1, testing image rescaling and rechanneling)\n",
    "\n",
    "X_images = X.reshape(-1, 224, 224, 1)\n",
    "\n",
    "X_images = X_images.astype('float32') / 255.0\n",
    "y_labels = y  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).shuffle(1000)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n",
    "tru = np.repeat(X_images, 3, axis=-1)\n",
    "\n",
    "tru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e19cb749-9f11-44ba-b1b0-1aaf527da3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: RESNET 50 (Part 2)\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "X_images = X.reshape(-1, 224, 224, 1)\n",
    "\n",
    "X_rgb = np.repeat(X_images, 3, axis=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rgb, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).shuffle(1000)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e274fa5-7bf1-4ccd-9663-b91f4e2dc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: RESNET 50 (Part 3)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze pretrained layers\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(len(np.unique(y)), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a0eebdb-ee2c-4bde-9119-8f9c871e20fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (3256, 224, 224, 3)\n",
      "Epoch 1/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 629ms/step - accuracy: 0.7990 - loss: 0.5055 - val_accuracy: 0.9417 - val_loss: 0.1849\n",
      "Epoch 2/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 619ms/step - accuracy: 0.9466 - loss: 0.1489 - val_accuracy: 0.9540 - val_loss: 0.1448\n",
      "Epoch 3/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 619ms/step - accuracy: 0.9605 - loss: 0.1197 - val_accuracy: 0.9202 - val_loss: 0.2430\n",
      "Epoch 4/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 618ms/step - accuracy: 0.9563 - loss: 0.1215 - val_accuracy: 0.9586 - val_loss: 0.1228\n",
      "Epoch 5/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 620ms/step - accuracy: 0.9800 - loss: 0.0805 - val_accuracy: 0.9663 - val_loss: 0.1213\n",
      "Epoch 6/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 621ms/step - accuracy: 0.9721 - loss: 0.0767 - val_accuracy: 0.9571 - val_loss: 0.1263\n",
      "Epoch 7/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 631ms/step - accuracy: 0.9826 - loss: 0.0581 - val_accuracy: 0.9509 - val_loss: 0.1342\n",
      "Epoch 8/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 621ms/step - accuracy: 0.9768 - loss: 0.0674 - val_accuracy: 0.9540 - val_loss: 0.1299\n",
      "Epoch 9/9\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 619ms/step - accuracy: 0.9828 - loss: 0.0493 - val_accuracy: 0.9540 - val_loss: 0.1212\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step\n",
      "Accuracy: 0.9539877300613497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       108\n",
      "           1       0.92      0.97      0.95       182\n",
      "           2       0.97      0.96      0.96       194\n",
      "           3       0.96      0.99      0.98       168\n",
      "\n",
      "    accuracy                           0.95       652\n",
      "   macro avg       0.96      0.94      0.95       652\n",
      "weighted avg       0.96      0.95      0.95       652\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 20:45:30.265740: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# MODEL: RESNET 50 (Part 4)\n",
    "\n",
    "print(\"Input shape:\", X_rgb.shape)\n",
    "\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=9)\n",
    "\n",
    "\n",
    "y_probs = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_probs, axis=1)\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56484b5e-6038-460e-8171-ef4edece70d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing model for use without retraining/deployment \n",
    "\n",
    "leukemia_screener = model\n",
    "\n",
    "with open('leukemia_screener.pkl', 'wb') as f:\n",
    "    pickle.dump(leukemia_screener, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09398218-1245-48c7-b9f7-3661b5903797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
